{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport io\\nimport requests\\nimport time\\n \\ndef google_stocks(symbol, startdate = (1, 1, 2005), enddate = None):\\n \\n    startdate = str(startdate[0]) + \\'+\\' + str(startdate[1]) + \\'+\\' + str(startdate[2])\\n \\n    if not enddate:\\n        enddate = time.strftime(\"%m+%d+%Y\")\\n    else:\\n        enddate = str(enddate[0]) + \\'+\\' + str(enddate[1]) + \\'+\\' + str(enddate[2])\\n \\n    stock_url = \"http://www.google.com/finance/historical?q=\" + symbol +                 \"&startdate=\" + startdate + \"&enddate=\" + enddate + \"&output=csv\"\\n \\n    raw_response = requests.get(stock_url).content\\n \\n    stock_data = pd.read_csv(io.StringIO(raw_response.decode(\\'utf-8\\')))\\n \\n    return stock_data\\n \\n \\nif __name__ == \\'__main__\\':\\n    apple_data = google_stocks(\\'AAPL\\')\\n    print(apple_data)\\n \\n    apple_truncated = google_stocks(\\'AAPL\\', enddate = (1, 1, 2006))\\n    print(apple_truncated)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tweepy\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "from textblob import TextBlob\n",
    "\n",
    "# First we login into twitter\n",
    "consumer_key = 'ICKsvPpVq8O4YWSzFNyQRQGFw'\n",
    "consumer_secret = 'L0MlmOCfOThlHwe19FRJsfQ5iYB5gZ6Qh3ASV9f0SBoX9O8rDV'\n",
    "access_token = '900139361915641856-v1aedUJsF9UCdmO0Z9KQkeSJDfBq9fJ'\n",
    "access_token_secret = 'ad0cOH8AzhJtLKyuqUJZOybSdsvianRpJyUwpyK4nQX6U'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "user = tweepy.API(auth)\n",
    "\n",
    "# Where the csv file will live\n",
    "FILE_NAME = 'historical.csv'\n",
    "\n",
    "\n",
    "# def stock_sentiment(quote, num_tweets):\n",
    "#     # Checks if the sentiment for our quote is\n",
    "#     # positive or negative, returns True if\n",
    "#     # majority of valid tweets have positive sentiment\n",
    "#     list_of_tweets = user.search(quote, count=num_tweets)\n",
    "    \n",
    "#     positive, null = 0, 0\n",
    "\n",
    "#     for tweet in list_of_tweets:\n",
    "#         blob = TextBlob(tweet.text).sentiment\n",
    "#         if blob.subjectivity == 0:\n",
    "#             null += 1\n",
    "#             next\n",
    "#         if blob.polarity > 0:\n",
    "#             positive += 1\n",
    "\n",
    "#     if positive > ((num_tweets - null)/2):\n",
    "#         return True\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import time\n",
    " \n",
    "def google_stocks(symbol, startdate = (1, 1, 2005), enddate = None):\n",
    " \n",
    "    startdate = str(startdate[0]) + '+' + str(startdate[1]) + '+' + str(startdate[2])\n",
    " \n",
    "    if not enddate:\n",
    "        enddate = time.strftime(\"%m+%d+%Y\")\n",
    "    else:\n",
    "        enddate = str(enddate[0]) + '+' + str(enddate[1]) + '+' + str(enddate[2])\n",
    " \n",
    "    stock_url = \"http://www.google.com/finance/historical?q=\" + symbol + \\\n",
    "                \"&startdate=\" + startdate + \"&enddate=\" + enddate + \"&output=csv\"\n",
    " \n",
    "    raw_response = requests.get(stock_url).content\n",
    " \n",
    "    stock_data = pd.read_csv(io.StringIO(raw_response.decode('utf-8')))\n",
    " \n",
    "    return stock_data\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    apple_data = google_stocks('AAPL')\n",
    "    print(apple_data)\n",
    " \n",
    "    apple_truncated = google_stocks('AAPL', enddate = (1, 1, 2006))\n",
    "    print(apple_truncated)\n",
    "\"\"\"\n",
    "\n",
    "# def get_historical(quote):\n",
    "#     # Download our file from google finance\n",
    "#     url = 'http://www.google.com/finance/historical?q=NASDAQ%3A'+quote+'&output=csv'\n",
    "    \n",
    "#     #startdate = (1, 1, 2017)\n",
    "#     #startdate = str(startdate[0]) + '+' + str(startdate[1]) + '+' + str(startdate[2])\n",
    "\n",
    "#     #url =\"http://www.google.com/finance/historical?q=\" + quote + \\\n",
    "#      #           \"&startdate=\" + startdate + \"&output=csv\"\n",
    "#     r = requests.get(url, stream=True)\n",
    "\n",
    "#     if r.status_code != 400:\n",
    "#         with open(FILE_NAME, 'wb') as f:\n",
    "#             for chunk in r:\n",
    "#                 f.write(chunk)\n",
    "\n",
    "#         return True\n",
    "\n",
    "\n",
    "# def stock_prediction():\n",
    "\n",
    "#     # Collect data points from csv\n",
    "#     dataset = []\n",
    "\n",
    "#     with open(FILE_NAME) as fr:\n",
    "#         for n, line in enumerate(fr):\n",
    "#             if n != 0:\n",
    "#                 dataset.append(float(line.split(',')[1]))\n",
    "\n",
    "#     dataset = np.array(dataset)\n",
    "\n",
    "#     # Create dataset matrix (X=t and Y=t+1)\n",
    "#     def create_dataset(dataset):\n",
    "#         dataX = [dataset[n+1] for n in range(len(dataset)-2)]\n",
    "#         return np.array(dataX), dataset[2:]\n",
    "        \n",
    "#     trainX, trainY = create_dataset(dataset)\n",
    "\n",
    "#     # Create and fit Multilinear Perceptron model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(8, input_dim=1, activation='relu'))\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     model.fit(trainX, trainY, nb_epoch=200, batch_size=2, verbose=2)\n",
    "\n",
    "#     # Our prediction for tomorrow\n",
    "#     prediction = model.predict(np.array([dataset[0]]))\n",
    "#     print (\"The price will move from %s to %s\" % (dataset[0], prediction[0][0]))\n",
    "\n",
    "#     return prediction\n",
    "\n",
    "    \n",
    "# # Ask user for a stock quote\n",
    "# stock_quote = input(\"Enter a stock quote from NASDAQ (e.j: AAPL, FB, GOOGL): \").upper()\n",
    "\n",
    "# # Check if the stock sentiment is positve\n",
    "# if not stock_sentiment(stock_quote, num_tweets=100):\n",
    "#     print (\"This stock has bad sentiment, please re-run the script\")\n",
    "#     sys.exit()\n",
    "\n",
    "# # Check if we got the historical data\n",
    "# if not get_historical(stock_quote):\n",
    "#     print (\"Google returned a 404, please re-run the script and\")\n",
    "#     print (\"enter a valid stock quote from NASDAQ\")\n",
    "#     sys.exit()\n",
    "\n",
    "# # We have our file so we create the neural net and get the prediction\n",
    "# #print stock_prediction()\n",
    "# stock_prediction()\n",
    "\n",
    "# # We are done so we delete the csv file\n",
    "# os.remove(FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now=datetime.datetime.now().date()\n",
    "\n",
    "# Ask user for a stock quote\n",
    "# stock_quote = input(\"Enter a stock quote from NASDAQ (e.j: AAPL, FB, GOOGL, INTU, BAC, C, PTR, MSFT, FIT, DWDP, LNKD, TWTR, NVDA, SYMC, PYPL, BP): \").upper()\n",
    "\n",
    "stock_symbols = ['AAPL', 'FB', 'GOOGL', 'INTU', 'BAC', 'C', 'PTR', 'MSFT', 'FIT', 'DWDP', 'LNKD', 'TWTR', \\\n",
    "                 'NVDA', 'SYMC', 'PYPL', 'BP']\n",
    "filenames = ['polarityAAPL.dat', 'polarityFB.dat', 'polarityGOOGL.dat', 'polarityINTU.dat', 'polarityBAC.dat',\\\n",
    "            'polarityC.dat', 'polarityPTR.dat', 'polarityMSFT.dat', 'polarityFIT.dat', 'polarityDWDP.dat', \\\n",
    "            'polarityLNKD.dat', 'polarityTWTR.dat', 'polarityNVDA.dat', 'polaritySYMC.dat', 'polarityPYPL.dat',\\\n",
    "            'polarityBP.dat']\n",
    "\n",
    "def stock_sentiment(quote, num_tweets):\n",
    "    # Checks if the sentiment for our quote is\n",
    "    # positive or negative, returns True if\n",
    "    # majority of valid tweets have positive sentiment\n",
    "    list_of_tweets = user.search(quote, count=num_tweets)\n",
    "    \n",
    "#     positive, null = 0, 0\n",
    "\n",
    "    for tweet in list_of_tweets:\n",
    "        blob = TextBlob(tweet.text).sentiment\n",
    "#         if blob.subjectivity == 0:\n",
    "#         null += 1\n",
    "        polarity = blob.polarity\n",
    "        return polarity\n",
    "        \n",
    "# Check if the stock sentiment is positve\n",
    "for symbol, file in zip(stock_symbols, filenames):\n",
    "    polarity = stock_sentiment(symbol, num_tweets=100)\n",
    "    final = str(now) + \", \" + str(polarity)\n",
    "    f = open(file,'a')\n",
    "    f.writelines(final)\n",
    "    f.writelines(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8ed581e809e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The company stock symbol: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/manika/anaconda3/envs/stock/lib/python2.7/site-packages/ipykernel/ipkernel.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sys_eval_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_getpass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/manika/anaconda3/envs/stock/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/manika/anaconda3/envs/stock/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "symbol = input(\"The company stock symbol: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
